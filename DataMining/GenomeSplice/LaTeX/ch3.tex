\section{Predobrada podataka i izbor atributa}
\label{ch:ch3}

\subsection{Predobrada}
Za predobradu podataka korišten je programski jezik Python u kombinaciji sa paketom Pandas. Datoteka s podacima \textit{splice\_orig.csv} je učitana u Pandas DataFrame objekt te su dodani nazivi atributa: \textit{class}, \textit{id} i \textit{DNA}. Stupac \textit{id} je jedinstveni identifikator vrste za svaki red u tablici i zbog toga ga ne koristimo u analizi podataka. Stupac \textit{DNA} dijelimo na šezdeset stupaca, za svaki nukleotid u DNA nizu po jedan novi stupac, naziva dna\_x gdje x označava indeks nukleotida u originalnom nizu.

\begin{table}[!ht]
   \caption[Udjeli nukleotida u skupu podataka za dubinsku analizu]{
   \textbf{Udjeli nukleotida u skupu podataka za dubinsku analizu.} \textit{A, G, C i T čine značajnu većinu u skupu podatak. D, N, S i R čine neznatan dio skupa.}}
   \centering
   \begin{tabular}{||c | c | c ||}
   \hline
   Oznaka atributa & Broj atributa & Udio atributa (\%) \\ [0.5ex]
   \hline\hline
   A & 44475 & 23.244 \\
   T & 46298 & 24.196 \\
   G & 50226 & 26.249 \\
   C & 50281 & 26.278 \\
   D & 2  & 0.0010 \\
   N & 56 & 0.0293 \\
   S & 1  & 0.0005 \\
   R & 1  & 0.0005 \\ [1ex]
   \hline
   \end{tabular}
   \label{tab:udjeli}
\end{table}
Tablica \ref{tab:udjeli} pokazuje razdiobu jedinstvenih oznaka nukleotida. Vidimo da vrlo mali udio ima oznaku D, N, S ili R (ukupno n redaka). Dodati argument da bi se u slučaju zamjene N moglo dobiti mnogo instanci, ali da ne možemo znati u točno kojim varijantama dolaze. Zbog toga možemo izbaciti ove retke bez značajnog smanjenja skupa podataka za dubinsku analizu. S druge strane, na ovaj način sprječavamo da algoritam da previše važnosti podacima koji spadaju u ovu marginalnu skupinu (\textit{outliers}). Ovaj skup podatak spremljen je u datoteku \textit{splice\_filtered.csv}

\subsection{Vizualizacija atributa}

\subsection{Odabir atributa}
Pri kreiranju modela za dubinsku analizu podataka obično nije nužno koristiti sve dostupne atribute skupa podataka. U odabiru najboljih atributa za model primjenjuju se različite tehnike koje se u grubo mogu svrstati u tri kategorije. \textbf{Metode filtriranja} koriste najčešće različite statističke testove kako bi se odredila korelacija\footnote{termin korelacija ovdje koristimo u širem smislu, ne isključivo u statističkom kontekstu} između atributa i izlazne varijable (klase). Druga kategorija, \textbf{Metode omotavanja}\footnote{wrapper methods} koriste se podskup atributa nad kojim treniraju model. Na osnovu zaključaka iz ovog modela, dodaju se ili oduzimaju određeni atributi - problem odabira atributa svodi se na problem pretraživanja. \textbf{Ugrađene metode}\footnote{embedded methods} kombiniraju kvalitete filterskih i metoda omotavanja korištenjem algoritama koji imaju vlastite ugrađene metode selekcije atributa.

Algoritam stabla odlučivanja ima prirodno ugrađen mehanizam za odabir atributa. Najprije se u postupku konstrukcije rangiraju atributi, a zatim se u postupku podrezivanja smanjuje ukupan broj atributa. Neki istraživači zbog ovih karakteristika koriste stablo odlučivanja kao algoritam za odabir atributa koji će se zatim koristiti u drugom modelu (klasifikacija iili regresijski postupak). Budući da je procedura izgradnje stabla odlučivanja poprilično brza onda je moguće i koristiti sve atribute. Međutim, kako bi provjerili ovu hipotezu, kreirat ćemo i dodatne varijante stabla odlučivanja, nad atributima koje odaberemo pomoću Hi-Kvadrat testa.
\subsubsection{Hi-Kvadrat test}
Hi-Kvadrat je test nezavisnosti koji se koristi kako bi se odredilo postoji li značajna veza između dvije nominalne (kategorične) varijable. Frekvencija svake vrijednosti jedne nominalne varijable uspoređuju se sa kategorijama druge nominalne varijable. Nul-hipoteza 
%https://www.researchgate.net/publication/4219423\_Feature\_selection\_with\_decision\_tree\_criterion
